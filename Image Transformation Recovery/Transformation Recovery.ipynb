{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverTransformation(Image1, Image2):\n",
    "    plt.figure()\n",
    "    plt.imshow(Image1,cmap='gray')\n",
    "    points_1=plt.ginput(6, timeout=120)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(Image2,cmap='gray')\n",
    "    points_2=plt.ginput(6, timeout=120)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    points_1=np.array(points_1)\n",
    "    points_2=np.array(points_2)\n",
    "    \n",
    "    locs_1=points_1\n",
    "    locs_2=points_2\n",
    "     # Construct A matrix from selected locations of original image\n",
    "    A= np.zeros((2*locs_1.shape[0], 6))\n",
    "    print(A.shape)\n",
    "    for count, i in enumerate(range(0, A.shape[0], 2)):  \n",
    "\n",
    "        A[i,:]=   np.concatenate((locs_1[count,:], np.array([1,0,0,0])) , axis=0 )\n",
    "        A[i+1,:]= np.concatenate(( np.array([0,0,0]) , locs_1[count,:] , np.array([1]) ) , axis=0 )\n",
    "\n",
    "        \n",
    "    # Getting y vector from corresponding locations in transformed image    \n",
    "    y= locs_2.reshape((-1,1))\n",
    "\n",
    "    \n",
    "    # Getting transformation matrix\n",
    "    A_pinv =  np.linalg.pinv(A)\n",
    "    x= np.matmul(A_pinv,y)\n",
    "    T = x.reshape(2,3) # transformation matrix\n",
    "    \n",
    "    \n",
    "    # Applying affine transformation on original image\n",
    "    T_Image= cv.warpAffine( Image1, T , (Image2.shape[1], Image2.shape[0]  ) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Getting MSE between intensities of Image2 and transformed image\n",
    "    MSEPix= np.mean( (T_Image-Image2)**2 )\n",
    "    \n",
    "    \n",
    "    # Getting MSE between corresponding locations of Image2 and transformed locations\n",
    "    T_points= np.matmul(T,  np.vstack( (locs_1.T, np.ones((1, locs_1.T.shape[1]))) ))\n",
    "    MSECorPts = np.mean( (T_points-locs_2.T)**2 )\n",
    "    \n",
    "    \n",
    "    return MSEPix, MSECorPts, T, T_Image\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Image Arfa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "orignal=plt.imread('dataset/arfa1.jpg')\n",
    "transformed=plt.imread('dataset/arfa2.jpg')\n",
    "dim=orignal.ndim\n",
    "dim2=transformed.ndim\n",
    "if dim>2:\n",
    "    orignal = cv.cvtColor(orignal, cv.COLOR_RGB2GRAY)\n",
    "if dim2>2:\n",
    "    orignal = cv.cvtColor(transformed, cv.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6)\n"
     ]
    }
   ],
   "source": [
    "MSEpix,MSECorpts,T,T_image=recoverTransformation(orignal,transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEpix for pic arfa is  55.31878757455149\n",
      "MSECorpts for pic arfa is  808.2413578895959\n",
      "T Matrix for pic arfa is \n",
      " [[  0.84846728  -0.637913   175.89480528]\n",
      " [  0.84078031   0.80771421 -25.55616228]]\n"
     ]
    }
   ],
   "source": [
    "print(\"MSEpix for pic arfa is \",MSEpix)\n",
    "print(\"MSECorpts for pic arfa is \",MSECorpts)\n",
    "print(\"T Matrix for pic arfa is \\n\",np.array(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imsave('results/arfa1_transformed.jpg',T_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Image Mecca1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "orignal=plt.imread('dataset/mecca1.jpg')\n",
    "transformed=plt.imread('dataset/mecca2.jpg')\n",
    "dim=orignal.ndim\n",
    "dim2=transformed.ndim\n",
    "if dim>2:\n",
    "    orignal = cv.cvtColor(orignal, cv.COLOR_RGB2GRAY)\n",
    "if dim2>2:\n",
    "    transformed = cv.cvtColor(transformed, cv.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6)\n",
      "MSEpix for pic arfa is  24.930153759685254\n",
      "MSECorpts for pic arfa is  16.59444003064156\n",
      "T Matrix for pic arfa is \n",
      " [[ -0.62128735  -0.92216581 360.35829471]\n",
      " [  0.86648825  -0.62024069 164.27890655]]\n"
     ]
    }
   ],
   "source": [
    "MSEpix,MSECorpts,T,T_image=recoverTransformation(orignal,transformed)\n",
    "print(\"MSEpix for pic arfa is \",MSEpix)\n",
    "print(\"MSECorpts for pic arfa is \",MSECorpts)\n",
    "print(\"T Matrix for pic arfa is \\n\",np.array(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imsave('results/mecca1_transformed.jpg',T_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Station image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "orignal=plt.imread('dataset/station1.png')\n",
    "transformed=plt.imread('dataset/station2.png')\n",
    "dim=orignal.ndim\n",
    "dim2=transformed.ndim\n",
    "if dim>2:\n",
    "    orignal = cv.cvtColor(orignal, cv.COLOR_RGB2GRAY)\n",
    "if dim2>2:\n",
    "    transformed = cv.cvtColor(transformed, cv.COLOR_RGB2GRAY)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6)\n",
      "MSEpix for pic Station is  0.05727981\n",
      "MSECorpts for pic Station is  5.185799912239278\n",
      "T Matrix for pic Station is \n",
      " [[  0.98723762  -0.37455685  70.94484564]\n",
      " [  0.37046499   0.89740519 -71.68947094]]\n"
     ]
    }
   ],
   "source": [
    "MSEpix,MSECorpts,T,T_image=recoverTransformation(orignal,transformed)\n",
    "print(\"MSEpix for pic Station is \",MSEpix)\n",
    "print(\"MSECorpts for pic Station is \",MSECorpts)\n",
    "print(\"T Matrix for pic Station is \\n\",np.array(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imsave('results/Station1_transformed.jpg',T_image,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
